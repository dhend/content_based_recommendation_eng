{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether these packages have been installed yet\n",
    "#nltk, scikit-learn, pandas\n",
    "#('python3 -m pip install scikit-learn')\n",
    "#('python3 -m pip install pandas')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "data = pd.read_csv(\"/Users/dhend/Rimsys/rimsys_dev_v2/public/Aug25_feeds.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def remove_urls(text):\n",
    "\turl_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\treturn url_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "#remove stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "#remove punctuations\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',PUNCT_TO_REMOVE))\n",
    "\n",
    "\n",
    "#df.to_csv('Aug4_preprocessed.csv')\n",
    "#remove stemming words: derived words to their word stem: walks, walking\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "def preProcess(text):\n",
    "\ttemp = text.lower()\n",
    "\ttemp = remove_urls(temp)\n",
    "\ttemp = remove_stopwords(temp)\n",
    "\ttemp = remove_punctuation(temp)\n",
    "\treturn temp\n",
    "\n",
    "def stemProcess(text):\n",
    "\ttext = stem_words(text)\n",
    "\treturn text\n",
    "\n",
    "def lemProcess(text):\n",
    "\ttext = lemmatize_words(text)\n",
    "\treturn text\n",
    "\n",
    "df['preprocessed_title'] = df['title'].astype('str').apply(lambda text: preProcess(text))\n",
    "df['preprocessed_description'] = df['description'].astype('str').apply(lambda text: preProcess(text))\n",
    "df[\"description_stemmed\"] = df[\"preprocessed_description\"].astype(\"str\").apply(lambda text: stemProcess(text))\n",
    "df['description_lem'] = df['preprocessed_description'].astype(\"str\").apply(lambda text: lemProcess(text))\n",
    "df.to_csv('Aug25_feeds.csv',index = False)\n",
    "# sample = df['description_lem'][1]\n",
    "# print(sample)\n",
    "# print(\"\\n\")\n",
    "# print(df[\"text_stemmed\"][1])\n",
    "#print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
